## Abstract

Autonomous mobile robots need to operate in a diverse range of environments that present large challenges for the current state of the art in perception. For example, autonomous road vehicles need to operate in darkness and fog and search-and-rescue robots need to operate in the presence of thick smoke. These conditions, referred to as Visually Degraded Environments (VDEs), degrade the performance of cameras and LiDAR and this degradation can easily lead to higher-level failures. Further, in many cases robots require perception in VDEs far exceeding that of humans. Autonomous road vehicles, for example, must operate in VDEs, but a perception failure could endanger human lives. If techniques for robust perception in VDEs are not developed, the usefulness of autonomous mobile robots will be severely limited.

This workshop aims to highlight new developments in the field of robust perception and state estimation. We will bring together experts in the field to share their work on novel sensors, new algorithms, and full perception systems. Our goal is to bring more attention to this important area, and encourage sharing and collaboration between robust, resilient perception and a diverse range of related research areas including computer vision, robust AI, and field robotics.


### Organizers
[Chris Heckman](http://www.ristoffer.ch/) - point of contact  
[Andrew Kramer](http://www.andrewjkramer.net/) - point of contact  
[Ali Agha](http://aliagha.site/)  
[Kostas Alexis](http://www.kostasalexis.com/)  
[Luca Carlone](https://lucacarlone.mit.edu/)  
[Margarita Chli](http://www.v4rl.ethz.ch)  


### Keynote Talks

Recordings of the keynote talks are available at the links below.

**Davide Scaramuzza** - [*Robust Perception For Cars And Drones*](https://youtu.be/s5LL0NYbI-U)  
**CJ Taylor** - [*UPSLAM : Union of Panoramas SLAM*](https://youtu.be/zR2uR1hCcL0)  
**Sebastian Scherer** - [*Robust  Navigation  with  Visual  and  Thermal  Sensors  in Degraded Visual Environments*](https://youtu.be/KH5_eCivG7M)  
**Jeanette Bohg** - [*Detect, Reject, Correct: Cross-modal Compensation of Corrupted Sensors*](https://youtu.be/fTwtz_aXnD8)  
**Claire Tomlin** - [*Learning-Based Waypoint Navigation: a Viewpoint on Perception, Planning, and Control*](https://youtu.be/wg-D-KTbtnw)  
**Larry Matthies** - [*Terrain-relative navigation for guided descent on Titan*](https://youtu.be/KFyl3MlLv1Y)  
**Sanjiv Singh** - [*Faster, Lighter, More Reliable: Commonplace autonomous systems need all three*](https://youtu.be/eti0Txui89k)  
**Tim Barfoot** - [*Dark,  Damp,  and  Dynamic:  Recent  Progress  on  Robotic Localization in Challenging Environments*](https://youtu.be/KUKGSwTZ9CI)


### Contributed Papers
Participants are invited to submit short papers (up to 4 pages in ICRA format) focusing on advances in robust perception using novel sensors, new algorithms, and full perception systems. 
 
Topics of interest include but are not limited to:
The use of novel or unusual sensor types for perception problems such as radar and thermal imaging
New methods for using traditional sensors (vision, lidar, etc) in challenging environments
Novel algorithms for robust perception and state estimation in challenging environments
Full perception stacks designed for challenging environments
Contributed papers will be reviewed by the organizers and a program committee of invited reviewers. Accepted papers will be published on the workshop website and will be featured in spotlight presentations and poster sessions. 


### Further Information
Please send any questions to Andrew Kramer at [andrew.kramer@colorado.edu](andrew.kramer@colorado.edu). Please include "Robust Perception ICRA 2021 Workshop" in the subject of the email.
