## Abstract

Autonomous mobile robots need to operate in a diverse range of environments that present large challenges for the current state of the art in perception. For example, autonomous road vehicles need to operate in darkness and fog and search-and-rescue robots need to operate in the presence of thick smoke. These conditions, referred to as Visually Degraded Environments (VDEs), degrade the performance of cameras and LiDAR and this degradation can easily lead to higher-level failures. Further, in many cases robots require perception in VDEs far exceeding that of humans. Autonomous road vehicles, for example, must operate in VDEs, but a perception failure could endanger human lives. If techniques for robust perception in VDEs are not developed, the usefulness of autonomous mobile robots will be severely limited.

This workshop aims to highlight new developments in the field of robust perception and state estimation. We will bring together experts in the field to share their work on novel sensors, new algorithms, and full perception systems. Our goal is to bring more attention to this important area, and encourage sharing and collaboration between robust, resilient perception and a diverse range of related research areas including computer vision, robust AI, and field robotics.


### Organizers
[Chris Heckman](http://www.ristoffer.ch/) - point of contact  
[Andrew Kramer](http://www.andrewjkramer.net/) - point of contact  
[Ali Agha](http://aliagha.site/)  
[Kostas Alexis](http://www.kostasalexis.com/)  
[Luca Carlone](https://lucacarlone.mit.edu/)  
[Margarita Chli](http://www.v4rl.ethz.ch)  


### Keynote Talks

**Davide Scaramuzza** - [*Robust Perception For Cars And Drones*](https://youtu.be/s5LL0NYbI-U)  
**CJ Taylor** - [*UPSLAM : Union of Panoramas SLAM*](https://youtu.be/zR2uR1hCcL0)  
**Sebastian Scherer** - [*Robust  Navigation  with  Visual  and  Thermal  Sensors  in Degraded Visual Environments*](https://youtu.be/KH5_eCivG7M)  
**Jeanette Bohg** - [*Detect, Reject, Correct: Cross-modal Compensation of Corrupted Sensors*](https://youtu.be/fTwtz_aXnD8)  
**Claire Tomlin** - [*Learning-Based Waypoint Navigation: a Viewpoint on Perception, Planning, and Control*](https://youtu.be/wg-D-KTbtnw)  
**Larry Matthies** - [*Terrain-relative navigation for guided descent on Titan*](https://youtu.be/KFyl3MlLv1Y)  
**Sanjiv Singh** - [*Faster, Lighter, More Reliable: Commonplace autonomous systems need all three*](https://youtu.be/eti0Txui89k)  
**Tim Barfoot** - [*Dark,  Damp,  and  Dynamic:  Recent  Progress  on  Robotic Localization in Challenging Environments*](https://youtu.be/KUKGSwTZ9CI)


### Contributed Papers

[*Self-Improving Semantic Perception on a Construction Robot*](papers/ICRA-21-WRPCE_paper_1.pdf) - Hermann Blum, Francesco Milano, René Zurbrügg, Roland Siegwart, Cesar Cadena, and Abel Gawel  
[*Calibrating LiDAR and Camera using Semantic Mutual information*](papers/ICRA-21-WRPCE_paper_2.pdf) - 	Peng Jiang, Philip Osteen, and Srikanth Saripalli  
[*MIXER: A Principled Framework for Multimodal, Multiway Data Association*](papers/ICRA-21-WRPCE_paper_3.pdf) - Parker Lusk, Ronak Roy, Kaveh Fathian, and Jonathan How  
[*Autonomous Quadrotor Flight despite Rotor Failure with Onboard Vision Sensors: Frames vs. Events*](papers/ICRA-21-WRPCE_paper_5.pdf) - 	Sihao Sun, Giovanni Cioffi, and Davide Scaramuzza  
[*On the Design of Robust and Reliable Vision Front-Ends for Visually Degraded Environments*](papers/ICRA-21-WRPCE_paper_6.pdf) - 	Vikrant Shah, Jagatpreet Singh, Pushyami Kaveti, and Hanumant Singh  
[*Event-based Monocular Depth Prediction in Night Driving*](papers/ICRA-21-WRPCE_paper_7.pdf) - 	Javier Hidalgo-Carrió, Daniel Gehrig, and Davide Scaramuzza  
[*Redesigning SLAM for Arbitrary Multi-Camera Systems*](papers/ICRA-21-WRPCE_paper_8.pdf) - 	Juichung Kuo, Manasi Muglikar, Zichao Zhang, and Davide Scaramuzza  
[*High-Speed Drone Flight with On-Board Sensing and Computing*](papers/ICRA-21-WRPCE_paper_9.pdf) - Antonio Loquercio, Elia Kaufmann, Yunlong Song, and Davide Scaramuzza  
[*Inertial Learning for Improved Dynamic Legged Robot State Estimation*](papers/ICRA-21-WRPCE_paper_10.pdf) - 	Russell Buchanan, Marco Camurri, and Maurice Fallon  


### Further Information
Please send any questions to Andrew Kramer at [andrew.kramer@colorado.edu](andrew.kramer@colorado.edu). Please include "Robust Perception ICRA 2021 Workshop" in the subject of the email.
